{"cells":[{"cell_type":"markdown","metadata":{"id":"sXm7lWtd9hKt"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/16Qnhwl9fyWvi7XZiz8EAsBDOm5uNUhi5)"]},{"cell_type":"markdown","metadata":{"id":"zCXzjlwW9bBG"},"source":["# Problem 1"]},{"cell_type":"markdown","metadata":{"id":"4Yiefrgg9bBI"},"source":["Use this notebook to write your code for problem 1. Some example code, and a plotting function for drawing decision boundaries, are given below."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kzPzGwNt9bBJ"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import Ridge\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"HBcs8EbU9bBK"},"source":["### Load the data:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests\n","\n","url_dict = {\n","    'problem1data1.txt': 'https://drive.google.com/uc?export=download&id=1gY8AYoB2pdNbmnA31m-5W_otLREZcbGG',\n","}\n","\n","def download_file(file_path):\n","    url = url_dict[file_path]\n","    print('Start downloading...')\n","    with requests.get(url, stream=True) as r:\n","        r.raise_for_status()\n","        with open(file_path, 'wb') as f:\n","            for chunk in r.iter_content(chunk_size=1024 * 1024 * 1024):\n","                f.write(chunk)\n","    print('Complete')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dL65dCeG9bBK"},"outputs":[],"source":["download_file('problem1data1.txt')\n","data = np.loadtxt('problem1data1.txt')\n","X = data[:, :2]\n","y = data[:, 2]"]},{"cell_type":"markdown","metadata":{"id":"QSVx-boP9bBK"},"source":["### The function make_plot below is a helper function for plotting decision boundaries; you should not need to change it."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8IuPK9wO9bBL"},"outputs":[],"source":["def make_plot(X, y, clf, title, filename):\n","    '''\n","    Plots the decision boundary of the classifier <clf> (assumed to have been fitted\n","    to X via clf.fit()) against the matrix of examples X with corresponding labels y.\n","\n","    Uses <title> as the title of the plot, saving the plot to <filename>.\n","\n","    Note that X is expected to be a 2D numpy array of shape (num_samples, num_dims).\n","    '''\n","    # Create a mesh of points at which to evaluate our classifier\n","    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n","                         np.arange(y_min, y_max, 0.02))\n","\n","    # Plot the decision boundary. For that, we will assign a color to each\n","    # point in the mesh [x_min, x_max]x[y_min, y_max].\n","    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","    # binarize\n","    Z = np.where(Z > 0, np.ones(len(Z)), -1 * np.ones(len(Z)))\n","\n","    # Put the result into a color plot\n","    Z = Z.reshape(xx.shape)\n","    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8, vmin=-1, vmax=1)\n","\n","    # Also plot the training points\n","    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n","    plt.xlabel('x1')\n","    plt.ylabel('x2')\n","    plt.xlim(xx.min(), xx.max())\n","    plt.ylim(yy.min(), yy.max())\n","    plt.xticks(())\n","    plt.yticks(())\n","    plt.title(title)\n","    plt.savefig(filename)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"V02r-bi09bBL"},"source":["## Here is some example code for performing regression with scikit-learn.\n","This section is not part of the problem! It demonstrates usage of the Ridge regression function, in particular illustrating what happens when the regularization strength is set to an overly-large number."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ioId-J9e9bBM","outputId":"b4142ea6-0eb0-4ec3-f391-d2790e64fb07"},"outputs":[],"source":["# Instantiate a Ridge regression object:\n","ridge = Ridge(alpha = 200)\n","\n","# Generate some fake data: y is linearly dependent on x, plus some noise.\n","n_pts = 40\n","\n","x = np.linspace(0, 5, n_pts)\n","y = 5 * x + np.random.randn(n_pts) + 2\n","\n","x = np.reshape(x, (-1, 1))   # Ridge regression function expects a 2D matrix\n","\n","plt.figure()\n","plt.plot(x, y, marker = 'o', linewidth = 0)\n","\n","ridge.fit(x, y)   # Fit the ridge regression model to the data\n","print('Ridge regression fit y = %fx + %f' % (ridge.coef_, ridge.intercept_))\n","\n","# Add ridge regression line to the plot:\n","plt.plot(x, ridge.coef_ * x + ridge.intercept_, color = 'red')\n","plt.legend(['data', 'Ridge Regression Fit'])\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.title('Ridge Regression with High Regularization')"]},{"cell_type":"markdown","metadata":{"id":"jSstHn7l9bBM"},"source":["# Your code for problem 1"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"X2rR32GA9bBM"},"outputs":[],"source":["#==============================================\n","# TODO: Implement your code for Problem 1 here.\n","# Use as many cells as you need.\n","#=============================================="]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
